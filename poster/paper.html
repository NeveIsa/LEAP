<!DOCTYPE html><script src="https://cdn.jsdelivr.net/npm/texme@1.2.2"></script>
<style>
body main{
    background-color: white;
}
.diagram-iframe {
    width: 100%;
    height: 600px;
    border: 1px solid #ddd;
    border-radius: 8px;
    margin: 20px 0;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
}
.diagram-iframe.tall {
    height: 750px;
}
.diagram-iframe.compact {
    height: 500px;
}
</style>
<textarea>

# Interactive Computational Learning Platform:
## A Unified Framework for Algorithm Exploration, Real-Time Analytics, and Live Assessment

### Abstract
Computational education benefits from approaches that engage students with algorithmic thinking while providing instructors actionable insights into learning processes. Traditional lecture-based approaches often lack mechanisms to capture the iterative nature of computational problem-solving. We present a **distributed interactive learning platform** that transforms instructor-authored Python functions into accessible HTTP endpoints, enabling real-time algorithmic exploration with comprehensive analytics. 

The platform organizes content as modular "experiments" containing callable functions across domains including numerical methods, graph algorithms, Monte Carlo simulations, differential equations, and linear algebra. Students interact through multiple client types—Python scripts, Jupyter notebooks, or command-line interfaces—while all function calls are logged for analysis. The system includes unified authentication across experiments and supports assessment through Markdown-authored quizzes with LaTeX mathematical notation.

We describe the system architecture, instructor workflow, and deployment patterns. Our evaluation combines interaction log analysis with learning assessments. The platform is available as open-source software for educational use.

---

## 1. Introduction and Motivation
Active learning methodologies have demonstrated significant efficacy in computational education, yet conventional classroom environments predominantly rely on static presentations, whiteboard demonstrations, or isolated computing environments. These traditional approaches constrain instructors' capacity to monitor student engagement, capture learning processes, and deliver immediate, personalized feedback at scale.

This work addresses these limitations through a platform that exposes instructor-authored Python functions as HTTP endpoints. The system supports multiple computational domains including numerical methods, optimization, graph algorithms, Monte Carlo simulations, and differential equations. Interaction logging enables monitoring and analysis of student learning patterns and algorithmic exploration strategies.

---

## 2. System Architecture and Implementation
**2.1 Core Infrastructure**

The platform uses a RESTful architecture built on FastAPI, providing access to computational functions:

- **`/functions`** — Dynamic function discovery and signature introspection
- **`/call`** — Synchronous function execution with comprehensive error handling
- **`/logs`** — Flexible querying interface supporting temporal and contextual filtering
- **`/experiments`** — Session management and experiment lifecycle control
- **`/admin`** — Authentication and administrative operations

**2.2 Modular Experiment Architecture**

Pedagogical content follows a **self-contained module design** enabling independent deployment:

```
experiments/<module>/
├── funcs/          # Instructor-authored computational functions
├── ui/             # Interactive dashboards and visualizations  
├── quiz/           # Assessment materials (Markdown + LaTeX)
└── db/             # Isolated DuckDB analytics store
```

This design allows multiple experiments to run while sharing a common API.

**2.3 Analytics Infrastructure**

Every student interaction generates a **structured log entry** preserving:
- Function invocation details (name, arguments, timestamp)
- Execution results or comprehensive error traces
- Session context (student ID, experiment, trial identification)
- Performance metrics (execution time, resource utilization)

DuckDB's **columnar storage engine** enables efficient analytics queries over extensive interaction datasets, supporting real-time dashboards and longitudinal analysis.

**2.4 Security and Authentication**

The platform uses unified authentication across all experiments:

- **PBKDF2 credential hashing** (240,000 iterations, SHA-256)
- **Session-based access control** with configurable timeouts
- **Global authentication scope** enabling seamless cross-experiment navigation
- **Data isolation** maintaining experiment-level privacy boundaries

**Figure 1: System Architecture**

<iframe src="architecture-diagram-concise.html" class="diagram-iframe compact" title="System Architecture Diagram" style="height: 400px;"></iframe>

*(Figure 1: System architecture showing the distributed client-server model with persistent logging layer.)*

**Performance and Scalability.** The lightweight architecture supports concurrent multi-user sessions while maintaining low latency response times. DuckDB's columnar storage provides efficient analytics queries even with extensive interaction histories.

**Deployment Flexibility.** The system can be deployed locally for individual courses, on institutional servers for department-wide use, or in cloud environments for large-scale implementations. Docker containerization ensures consistent deployment across different platforms.

---

## 3. Computational Domains and Pedagogical Applications

**3.1 Mathematical Analysis and Numerical Methods**

The platform supports interactive exploration of classical numerical algorithms:

- **Root-finding:** Students compare convergence behavior of bisection, Newton-Raphson, and secant methods, investigating how function properties and initial conditions affect algorithmic performance
- **Multidimensional optimization:** JAX-accelerated automatic differentiation enables real-time gradient descent exploration on complex landscapes with immediate convergence visualization
- **Differential equations:** Configurable Euler method implementation demonstrates step-size effects on solution accuracy and numerical stability
- **Linear algebra:** Power method experiments reveal eigenvalue computation dynamics and convergence characteristics

**3.2 Discrete Algorithms and Graph Theory**

Fundamental computer science algorithms become tangible through interactive exploration:

- **Graph traversal:** BFS and DFS implementations on structured 5×5 grids enable direct observation of algorithmic differences in search patterns and data structure behavior
- **Algorithmic complexity:** Students empirically investigate performance characteristics by varying problem parameters and observing execution patterns

**3.3 Stochastic Methods and Computational Statistics**

- **Monte Carlo simulation:** Pi estimation through geometric probability demonstrates stochastic convergence with real-time accuracy tracking
- **Statistical meta-analysis:** Logging infrastructure enables analysis of student exploration patterns and algorithmic choice distributions

**3.4 Assessment Integration and Real-Time Analytics**

- **Live assessment:** Markdown-authored quizzes with LaTeX mathematical notation integrate seamlessly with function call infrastructure
- **Instructor dashboards:** Real-time visibility into student exploration patterns, algorithmic choices, and conceptual difficulties
- **Learning analytics:** Persistent logging enables individual trajectory tracking and class-wide understanding evolution

**3.5 Multi-Modal Client Architecture**

The platform's client-agnostic design supports diverse interaction paradigms:

- **Python scripts:** Direct API integration enabling programmatic algorithmic exploration
- **Jupyter notebooks:** Rich computational narratives with embedded function calls and visualization
- **Command-line interfaces:** Lightweight interaction for focused algorithmic investigation
- **Web dashboards:** Browser-based exploration with real-time visualization components

This flexibility allows students to engage through their preferred computational environment while ensuring consistent data capture and analytics across all interaction modes.

**Figure 2: User Interaction Flow**

<iframe src="user-flow-diagram-concise.html" class="diagram-iframe tall" title="User Interaction Flow Diagram" style="height: 800px;"></iframe>

---

## 4. Evaluation Framework and Empirical Results

**4.1 Deployment Methodology**

Initial implementations across diverse computational curricula employed mixed-methods evaluation combining quantitative interaction analytics with qualitative learning assessment:

**4.2 Engagement and Exploration Patterns**

Analysis of interaction logs from pilot deployments shows changes in student behavior:

- **Exploration patterns:** Students made more function calls per session compared to traditional assignments
- **Cross-domain usage:** Students used multiple experiment types within single sessions
- **Session length:** Interactive sessions showed increased engagement duration
- **Error correction:** Real-time feedback appeared to reduce time spent on errors

**4.3 Learning Outcomes Assessment**

Pre/post evaluation using computational thinking assessments shows:

- **Problem decomposition:** Improvement in breaking down algorithmic problems
- **Behavioral prediction:** Increased ability to anticipate algorithm performance
- **Knowledge transfer:** Some evidence of applying concepts across different algorithmic domains

**4.4 Instructor Adoption and Usability**

Instructor feedback indicates positive response to platform characteristics:

- **Setup time:** Deployment was faster than traditional lab configuration
- **Content creation:** Instructors could create new experiments efficiently
- **Monitoring:** Instructors reported better visibility into student activity during class

**4.5 Future Directions and Platform Evolution**

Ongoing development focuses on three primary areas:

- **Advanced visualization:** Algorithm convergence animations, multi-dimensional parameter space exploration, and interactive optimization landscape rendering
- **Intelligent analytics:** Machine learning-driven pattern recognition for automatic identification of student misconceptions and learning trajectory clustering
- **Ecosystem integration:** LMS connectivity and gradebook synchronization while maintaining deployment autonomy
- **Algorithm expansion:** Integration of advanced computational domains including machine learning, scientific computing, and computational geometry

---

## 5. Conclusions and Broader Impact

**5.1 Technical Contributions**

This work presents a platform approach that addresses some trade-offs between educational goals and implementation complexity. Key technical features include:

- **Unified authentication architecture** reducing cognitive load while maintaining security isolation
- **Language-agnostic API design** enabling diverse client ecosystem integration
- **Real-time analytics infrastructure** providing immediate instructional feedback at scale
- **Modular experiment architecture** supporting independent content development and deployment

**5.2 Pedagogical Impact**

Evaluation across 9 computational domains shows improvements in student engagement and learning outcomes. The platform's ability to capture granular interaction data provides insight into algorithmic learning processes, revealing patterns not easily visible in traditional assessment approaches.

**5.3 Educational Technology Access**

By open-sourcing this platform, we provide an alternative approach to computational education tools. The system's modest infrastructure requirements may enable adoption in various institutional contexts.

**5.4 Research Implications**

The comprehensive interaction logging infrastructure creates new opportunities for computational education research. Fine-grained behavioral data enables investigation of learning transfer between algorithmic domains, identification of common misconception patterns, and development of adaptive instructional interventions.

**Platform Status:** Current implementation includes 9 experiment environments covering numerical analysis, discrete algorithms, optimization, differential equations, linear algebra, and stochastic methods, with unified authentication across all experiments.

---

## References

**Pedagogical Foundations:**
- Freeman, S., et al. (2014). Active learning increases student performance in science, engineering, and mathematics. *Proceedings of the National Academy of Sciences*, 111(23), 8410-8415.
- Prince, M. (2004). Does active learning work? A review of the research. *Journal of Engineering Education*, 93(3), 223-231.
- Mazur, E. (1997). *Peer instruction: A user's manual*. Prentice Hall.

**Educational Technology:**
- Denny, P., et al. (2008). PeerWise: Students sharing their multiple choice questions. *ACM SIGCSE Bulletin*, 40(3), 282-286.
- Ihantola, P., et al. (2010). Review of recent systems for automatic assessment of programming assignments. *ACM Computing Surveys*, 43(3), 1-35.

**Computational Thinking:**
- Wing, J. M. (2006). Computational thinking. *Communications of the ACM*, 49(3), 33-35.
- Grover, S., & Pea, R. (2013). Computational thinking in K–12: A review of the state of the field. *Educational Researcher*, 42(1), 38-43.

**Platform Resources:**
- **Source Code:** https://github.com/NeveIsa/TeachingOptimization
- **Documentation:** [Platform deployment and authoring guides]
- **Demo Environment:** [Live institutional deployment when available]
